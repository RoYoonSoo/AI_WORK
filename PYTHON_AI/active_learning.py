import pandas as pd
import numpy as np
import torch
from torch import nn
import torch.nn.functional as F
from transformers import AutoTokenizer, AutoModel
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
import warnings
import os
import glob
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.utils.class_weight import compute_class_weight
import copy

# --- ê²½ê³  ë©”ì‹œì§€ ë¬´ì‹œ ë° í•œê¸€ í°íŠ¸ ì„¤ì • ---
warnings.filterwarnings('ignore')
try:
    font_name = fm.FontProperties(fname="c:/Windows/Fonts/malgun.ttf").get_name()
    plt.rc('font', family=font_name)
except FileNotFoundError:
    try:
        plt.rc('font', family='AppleGothic')
    except:
        print("í•œê¸€ í°íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê·¸ë˜í”„ì˜ ì œëª©ê³¼ ì¶•ì´ ê¹¨ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
plt.rcParams['axes.unicode_minus'] = False


# --- Focal Loss í´ë˜ìŠ¤ ì •ì˜ (ì´ì „ê³¼ ë™ì¼) ---
class FocalLoss(nn.Module):
    def __init__(self, alpha=None, gamma=2., reduction='mean'):
        super(FocalLoss, self).__init__()
        self.gamma = gamma
        self.alpha = alpha
        if isinstance(alpha, (float, int)): self.alpha = torch.Tensor([alpha, 1 - alpha])
        if isinstance(alpha, list): self.alpha = torch.Tensor(alpha)
        self.reduction = reduction

    def forward(self, inputs, targets):
        ce_loss = F.cross_entropy(inputs, targets, reduction='none')
        pt = torch.exp(-ce_loss)
        focal_loss = ((1 - pt) ** self.gamma * ce_loss)
        if self.alpha is not None:
            if self.alpha.type() != inputs.data.type():
                self.alpha = self.alpha.type_as(inputs.data)
            at = self.alpha.gather(0, targets.data.view(-1))
            focal_loss = at * focal_loss
        if self.reduction == 'mean':
            return focal_loss.mean()
        elif self.reduction == 'sum':
            return focal_loss.sum()
        else:
            return focal_loss


# --- ëª¨ë¸ í´ë˜ìŠ¤ ì •ì˜ (ì´ì „ê³¼ ë™ì¼) ---
class TextClassifier(nn.Module):
    def __init__(self, bert_model_name, num_classes=5):
        super().__init__()
        self.bert = AutoModel.from_pretrained(bert_model_name)
        self.classifier = nn.Linear(self.bert.config.hidden_size, num_classes)

    def forward(self, input_ids, attention_mask):
        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)
        cls_token_vector = outputs.last_hidden_state[:, 0, :]
        logits = self.classifier(cls_token_vector)
        return logits


# --- ë°ì´í„° ë¡œë“œ í•¨ìˆ˜ (ì´ì „ê³¼ ë™ì¼) ---
def load_data(human_labeled_folder, unlabeled_folder, label_map):
    print(f"'{human_labeled_folder}'ì—ì„œ ì‚¬ëŒì´ ë¼ë²¨ë§í•œ ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.")
    labeled_files = glob.glob(os.path.join(human_labeled_folder, '*.csv'))
    if not labeled_files:
        print(f"ì˜¤ë¥˜: '{human_labeled_folder}' í´ë”ì— CSV íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return None, None, None
    labeled_dfs = []
    for f in labeled_files:
        try:
            df = pd.read_csv(f, header=None, skiprows=1, on_bad_lines='skip', encoding='utf-8')
        except UnicodeDecodeError:
            df = pd.read_csv(f, header=None, skiprows=1, on_bad_lines='skip', encoding='cp949')
        labeled_dfs.append(df)
    human_labeled_df = pd.concat(labeled_dfs, ignore_index=True)
    human_labeled_df = human_labeled_df.iloc[:, [0, 3]].rename(columns={0: 'text', 3: 'label'})
    human_labeled_df.dropna(subset=['text', 'label'], inplace=True)
    human_labeled_df['text'] = human_labeled_df['text'].astype(str)
    human_labeled_df = human_labeled_df[human_labeled_df['text'].str.strip() != '']
    human_labeled_df['label_id'] = human_labeled_df['label'].map(label_map)
    human_labeled_df.dropna(subset=['label_id'], inplace=True)
    human_labeled_df['label_id'] = human_labeled_df['label_id'].astype(int)
    print(f"'{unlabeled_folder}'ì—ì„œ ë¼ë²¨ ì—†ëŠ” í›„ë³´ ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.")
    unlabeled_files = glob.glob(os.path.join(unlabeled_folder, '*.csv'))
    if not unlabeled_files:
        unlabeled_pool_df = pd.DataFrame(columns=['text'])
    else:
        unlabeled_dfs = []
        for f in unlabeled_files:
            try:
                df = pd.read_csv(f, header=None, skiprows=1, usecols=[0], on_bad_lines='skip', encoding='utf-8')
            except UnicodeDecodeError:
                df = pd.read_csv(f, header=None, skiprows=1, usecols=[0], on_bad_lines='skip', encoding='cp949')
            unlabeled_dfs.append(df)
        unlabeled_pool_df = pd.concat(unlabeled_dfs, ignore_index=True)
        unlabeled_pool_df.columns = ['text']
        unlabeled_pool_df.dropna(subset=['text'], inplace=True)
        unlabeled_pool_df['text'] = unlabeled_pool_df['text'].astype(str)
        unlabeled_pool_df = unlabeled_pool_df[unlabeled_pool_df['text'].str.strip() != '']
    return human_labeled_df, unlabeled_pool_df, label_map


# --- ì•™ìƒë¸” ì˜ˆì¸¡ í•¨ìˆ˜ (í”„ë¡¬í”„íŠ¸ ì ìš©) ---
def ensemble_predict(model, snapshots, tokenizer, texts, device, prompt, batch_size=32):
    model.to(device)
    all_avg_probs = None

    with torch.no_grad():
        for i, state_dict in enumerate(snapshots):
            model.load_state_dict(state_dict)
            model.eval()

            all_probs_snapshot = []
            for j in range(0, len(texts), batch_size):
                batch_texts = texts[j:j + batch_size]
                if not batch_texts: continue

                # [í”„ë¡¬í”„íŠ¸ ì ìš©]
                batch_texts_with_prompt = [prompt + text for text in batch_texts]
                inputs = tokenizer(batch_texts_with_prompt, return_tensors='pt', padding=True, truncation=True,
                                   max_length=128).to(device)

                logits = model(input_ids=inputs['input_ids'], attention_mask=inputs['attention_mask'])
                probabilities = F.softmax(logits, dim=1)
                all_probs_snapshot.append(probabilities.cpu())

            all_probs_tensor = torch.cat(all_probs_snapshot)
            if all_avg_probs is None:
                all_avg_probs = all_probs_tensor
            else:
                all_avg_probs += all_probs_tensor

    final_avg_probs = all_avg_probs / len(snapshots)
    final_preds = torch.argmax(final_avg_probs, dim=1)
    return final_preds


# --- ë©”ì¸ ì¸í„°ë™í‹°ë¸Œ í•¨ìˆ˜ ---
def run_advanced_pipeline():
    print("=" * 60);
    print("### ğŸš€ ìµœì¢… ì„±ëŠ¥ ê°œì„  íŒŒì´í”„ë¼ì¸ ì‹œì‘ (í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ ë²„ì „) ###");
    print("=" * 60)

    # --- í•˜ì´í¼íŒŒë¼ë¯¸í„° ---
    HUMAN_LABELED_FOLDER, UNLABELED_DATA_FOLDER = 'data', 'activeLearning'
    TEST_SET_RATIO, VALIDATION_SET_RATIO = 0.2, 0.2
    MODEL_NAME = "klue/roberta-base"  # ëª¨ë¸ êµì²´
    QUERY_SIZE = 10
    MINORITY_CLASS_IDS = [3, 4]
    PSEUDO_LABEL_THRESHOLD = 0.98
    MAX_PSEUDO_PER_CLASS = 70
    FOCAL_LOSS_GAMMA = 2.0
    ENSEMBLE_EPOCHS = 8

    # [ì¶”ê°€] í”„ë¡¬í”„íŠ¸ ì •ì˜
    PROMPT = "ëŒ“ê¸€ì„ ë¶„ë¥˜í•˜ì„¸ìš”. íŠ¹íˆ ì›¹íˆ° ë‚´ìš©ì— ëŒ€í•œ ëŒ“ê¸€ê³¼, ì‘ê°€ë‚˜ ê·¸ë¦¼ì— ëŒ€í•œ ë¹„íŒì„ êµ¬ë¶„í•˜ëŠ” ë° ì§‘ì¤‘í•˜ì„¸ìš”: "

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"\n--- í˜„ì¬ ì‚¬ìš© ì¥ì¹˜: {device} | ëª¨ë¸: {MODEL_NAME} ---")

    # --- ë°ì´í„° ì¤€ë¹„ ---
    print("\n--- 1ë‹¨ê³„: ë°ì´í„° ì¤€ë¹„ ë° ë¶„í•  ---")
    label_map = {"ì¹­ì°¬": 0, "ë¹„íŒ": 1, "ì‘í’ˆë‚´ìš©": 2, "ë…¼ìŸ": 3, "ê´€ë ¨ì—†ìŒ": 4}
    human_labeled_df, unlabeled_pool_df, _ = load_data(HUMAN_LABELED_FOLDER, UNLABELED_DATA_FOLDER, label_map)
    if human_labeled_df is None: return
    remaining_df, test_df = train_test_split(human_labeled_df, test_size=TEST_SET_RATIO, random_state=42,
                                             stratify=human_labeled_df['label_id'])
    labeled_df, validation_df = train_test_split(remaining_df, test_size=VALIDATION_SET_RATIO / (1 - TEST_SET_RATIO),
                                                 random_state=42, stratify=remaining_df['label_id'])
    known_labeled_texts = set(human_labeled_df['text'])
    unlabeled_pool_df = unlabeled_pool_df[~unlabeled_pool_df['text'].isin(known_labeled_texts)].reset_index(drop=True)
    print(f"  - í…ŒìŠ¤íŠ¸: {len(test_df)}ê°œ | ê²€ì¦: {len(validation_df)}ê°œ | ì´ˆê¸° í•™ìŠµ: {len(labeled_df)}ê°œ")
    print(f"  - ë¼ë²¨ ì—†ëŠ” í›„ë³´(Unlabeled Pool): {len(unlabeled_pool_df)}ê°œ")

    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)
    validation_accuracies = []
    initial_labeled_count = len(labeled_df)
    num_rounds = len(unlabeled_pool_df) // QUERY_SIZE if QUERY_SIZE > 0 else 0

    # --- ëª¨ë¸ ë° ì˜µí‹°ë§ˆì´ì € ìƒì„± ---
    print(f"\n--- 2ë‹¨ê³„: ë©”ì¸ ë¶„ë¥˜ ëª¨ë¸({MODEL_NAME}) ìƒì„± ---")
    model = TextClassifier(MODEL_NAME, num_classes=len(label_map)).to(device)
    optim = torch.optim.AdamW(model.parameters(), lr=1e-5)

    # --- ì•¡í‹°ë¸Œ ëŸ¬ë‹ ë£¨í”„ ---
    print(f"\n--- 3ë‹¨ê³„: ì•¡í‹°ë¸Œ ëŸ¬ë‹ ë£¨í”„ ì‹œì‘ (ì´ {num_rounds}ë¼ìš´ë“œ ì˜ˆìƒ) ---")
    for i in range(num_rounds + 1):
        print(f"\nğŸ”„ ë¼ìš´ë“œ {i + 1} (í˜„ì¬ í•™ìŠµ ë¼ë²¨ ìˆ˜: {len(labeled_df)})")

        # --- í•™ìŠµ ---
        train_texts = labeled_df['text'].tolist()
        train_labels = torch.tensor(labeled_df['label_id'].tolist(), dtype=torch.long)
        class_weights = compute_class_weight('balanced', classes=np.unique(train_labels.numpy()),
                                             y=train_labels.numpy())
        class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)
        criterion = FocalLoss(gamma=FOCAL_LOSS_GAMMA, alpha=class_weights)

        model_snapshots = []
        print(f"  - ëª¨ë¸ í•™ìŠµ ë° ìŠ¤ëƒ…ìƒ· ì•™ìƒë¸” ìƒì„± (ì´ {ENSEMBLE_EPOCHS} ì—í¬í¬)...")
        for epoch in range(ENSEMBLE_EPOCHS):
            model.train()
            permutation = torch.randperm(len(train_texts))
            for j in range(0, len(train_texts), 8):  # ë°°ì¹˜ ì‚¬ì´ì¦ˆ ì¡°ì ˆ (roberta-large)
                indices = permutation[j:j + 8]
                batch_texts = [train_texts[k] for k in indices]
                batch_labels = train_labels[indices].to(device)
                if not batch_texts: continue

                # [í”„ë¡¬í”„íŠ¸ ì ìš©]
                batch_texts_with_prompt = [PROMPT + text for text in batch_texts]
                inputs = tokenizer(batch_texts_with_prompt, return_tensors='pt', padding=True, truncation=True,
                                   max_length=128).to(device)

                logits = model(input_ids=inputs['input_ids'], attention_mask=inputs['attention_mask'])
                loss = criterion(logits, batch_labels)
                optim.zero_grad();
                loss.backward();
                optim.step()

            print(f"    - ì—í¬í¬ {epoch + 1} ì™„ë£Œ, ìŠ¤ëƒ…ìƒ· ì €ì¥.")
            model_snapshots.append(copy.deepcopy(model.state_dict()))

        # --- ììœ¨ í•™ìŠµ (í”„ë¡¬í”„íŠ¸ ì ìš©) ---
        print("  - ğŸ§  ììœ¨ í•™ìŠµ ì‹œì‘...")
        model.eval()
        pseudo_labeled_rows = []
        unlabeled_texts_for_pseudo = unlabeled_pool_df['text'].dropna().tolist()
        if unlabeled_texts_for_pseudo:
            with torch.no_grad():
                for j in range(0, len(unlabeled_texts_for_pseudo), 16):  # ë°°ì¹˜ ì‚¬ì´ì¦ˆ ì¡°ì ˆ
                    batch_texts = unlabeled_texts_for_pseudo[j:j + 16]
                    if not batch_texts: continue

                    # [í”„ë¡¬í”„íŠ¸ ì ìš©]
                    batch_texts_with_prompt = [PROMPT + text for text in batch_texts]
                    inputs = tokenizer(batch_texts_with_prompt, return_tensors='pt', padding=True, truncation=True,
                                       max_length=128).to(device)

                    logits = model(input_ids=inputs['input_ids'], attention_mask=inputs['attention_mask'])
                    probabilities = F.softmax(logits, dim=1)
                    max_probs, preds = torch.max(probabilities, dim=1)
                    confident_mask = max_probs > PSEUDO_LABEL_THRESHOLD
                    if confident_mask.any():
                        confident_texts = np.array(batch_texts)[confident_mask.cpu().numpy()]
                        confident_preds = preds[confident_mask].cpu().numpy()
                        for text, pred_id in zip(confident_texts, confident_preds):
                            pseudo_labeled_rows.append({'text': text, 'label_id': pred_id})

        if pseudo_labeled_rows:
            pseudo_df = pd.DataFrame(pseudo_labeled_rows)
            pseudo_df = pseudo_df.groupby('label_id').head(MAX_PSEUDO_PER_CLASS).reset_index(drop=True)
            print(f"    - ëª¨ë¸ì´ í™•ì‹ í•˜ëŠ” ë°ì´í„° {len(pseudo_df)}ê°œë¥¼ ì˜ì‚¬ ë¼ë²¨ë¡œ ìƒì„±í•˜ì—¬ ì¶”ê°€ í•™ìŠµí•©ë‹ˆë‹¤.")

            augmented_texts = labeled_df['text'].tolist() + pseudo_df['text'].tolist()
            augmented_labels = torch.cat([torch.tensor(labeled_df['label_id'].tolist(), dtype=torch.long),
                                          torch.tensor(pseudo_df['label_id'].tolist(), dtype=torch.long)])
            model.train()
            for epoch in range(2):
                permutation = torch.randperm(len(augmented_texts))
                for j in range(0, len(augmented_texts), 8):  # ë°°ì¹˜ ì‚¬ì´ì¦ˆ ì¡°ì ˆ
                    indices = permutation[j:j + 8]
                    batch_texts = [augmented_texts[k] for k in indices]
                    batch_labels = augmented_labels[indices].to(device)
                    if not batch_texts: continue

                    # [í”„ë¡¬í”„íŠ¸ ì ìš©]
                    batch_texts_with_prompt = [PROMPT + text for text in batch_texts]
                    inputs = tokenizer(batch_texts_with_prompt, return_tensors='pt', padding=True, truncation=True,
                                       max_length=128).to(device)

                    logits = model(input_ids=inputs['input_ids'], attention_mask=inputs['attention_mask'])
                    loss = criterion(logits, batch_labels)
                    optim.zero_grad();
                    loss.backward();
                    optim.step()
        else:
            print("    - ì‹ ë¢°ë„ ë†’ì€ ì˜ì‚¬ ë¼ë²¨ì„ ì°¾ì§€ ëª»í•´ ììœ¨ í•™ìŠµì„ ê±´ë„ˆëœë‹ˆë‹¤.")

        # --- ì„±ëŠ¥ ì¸¡ì • (ì•™ìƒë¸” ì˜ˆì¸¡) ---
        val_texts, val_labels_cpu = validation_df['text'].tolist(), validation_df['label_id'].tolist()

        print("  - ì•™ìƒë¸” ëª¨ë¸ë¡œ ê²€ì¦ ì„¸íŠ¸ ì„±ëŠ¥ ì¸¡ì • ì¤‘...")
        all_preds_tensor = ensemble_predict(model, model_snapshots, tokenizer, val_texts, device, PROMPT)

        accuracy = accuracy_score(val_labels_cpu, all_preds_tensor.numpy())
        validation_accuracies.append(accuracy)
        print(f"  ğŸ“ˆ [ëª¨ì˜ê³ ì‚¬] ê²€ì¦ ì„¸íŠ¸ ì „ì²´ ì •í™•ë„ (ì•™ìƒë¸”): {accuracy:.2%}")

        target_names = [name for name, id in sorted(label_map.items(), key=lambda item: item[1])]
        y_true = np.array(val_labels_cpu)
        y_pred = all_preds_tensor.cpu().numpy()
        print("\n  --- ìƒì„¸ ë¶„ì„ ë¦¬í¬íŠ¸ ---")
        print(classification_report(y_true, y_pred, target_names=target_names, zero_division=0))
        print("  --- í˜¼ë™ í–‰ë ¬ (í–‰: ì‹¤ì œ, ì—´: ì˜ˆì¸¡) ---")
        cm = confusion_matrix(y_true, y_pred, labels=sorted(label_map.values()))
        print(pd.DataFrame(cm, index=target_names, columns=target_names))
        print("-" * 25)

        if len(unlabeled_pool_df) < QUERY_SIZE:
            print("\nëª¨ë“  ë°ì´í„°ë¥¼ ë¼ë²¨ë§í•˜ì—¬ ë£¨í”„ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break
        if input("\në¼ë²¨ë§ì„ ê³„ì†í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").strip().lower() != 'y':
            break

        # --- ë°ì´í„° ì„ ë³„ (í”„ë¡¬í”„íŠ¸ ì ìš©) ---
        print("  - ğŸ§  ë°ì´í„° ì„ ë³„ ì‹œì‘ (Uncertainty + Minority Targeting)...")
        model.eval()
        unlabeled_texts = unlabeled_pool_df['text'].dropna().tolist()
        all_probs = []
        with torch.no_grad():
            for j in range(0, len(unlabeled_texts), 16):  # ë°°ì¹˜ ì‚¬ì´ì¦ˆ ì¡°ì ˆ
                batch_texts = unlabeled_texts[j:j + 16]
                if not batch_texts: continue

                # [í”„ë¡¬í”„íŠ¸ ì ìš©]
                batch_texts_with_prompt = [PROMPT + text for text in batch_texts]
                inputs = tokenizer(batch_texts_with_prompt, return_tensors='pt', padding=True, truncation=True,
                                   max_length=128).to(device)

                logits = model(input_ids=inputs['input_ids'], attention_mask=inputs['attention_mask'])
                all_probs.append(F.softmax(logits, dim=1).cpu())
        all_probs_tensor = torch.cat(all_probs)
        # ... (ì´í•˜ ë°ì´í„° ì„ ë³„ ë° ì‚¬ìš©ì ë¼ë²¨ë§ ë¡œì§ì€ ì´ì „ê³¼ ë™ì¼)
        entropy = -torch.sum(all_probs_tensor * torch.log(all_probs_tensor + 1e-9), dim=1)
        uncertain_indices = torch.topk(entropy, k=min(QUERY_SIZE, len(unlabeled_texts))).indices
        max_probs, preds = torch.max(all_probs_tensor, dim=1)
        minority_mask = torch.isin(preds, torch.tensor(MINORITY_CLASS_IDS))
        candidate_indices = torch.where(minority_mask)[0]
        sorted_minority_indices = candidate_indices[torch.argsort(max_probs[candidate_indices], descending=True)]
        final_query_indices = list(uncertain_indices.numpy()[:QUERY_SIZE // 2])
        for idx in sorted_minority_indices.numpy():
            if len(final_query_indices) >= QUERY_SIZE: break
            if idx not in final_query_indices: final_query_indices.append(idx)
        i = 0
        while len(final_query_indices) < QUERY_SIZE and i < len(uncertain_indices):
            idx = uncertain_indices[i].item()
            if idx not in final_query_indices: final_query_indices.append(idx)
            i += 1
        questions_to_label = unlabeled_pool_df.iloc[final_query_indices]

        # --- ì‚¬ìš©ì ë¼ë²¨ë§ ---
        print("\n" + "-" * 20);
        print("âœï¸ ëª¨ë¸ì´ ì„ íƒí•œ ë°ì´í„°ì— ë¼ë²¨ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.");
        print("-" * 20)
        newly_labeled_rows = []
        for _, row in questions_to_label.iterrows():
            while True:
                print(f"\nëŒ“ê¸€: {row['text']}")
                user_input = input(f"ë¼ë²¨ ì…ë ¥ [{'/'.join(label_map.keys())}]: ").strip()
                if user_input in label_map:
                    new_row = row.to_dict();
                    new_row['label_id'] = label_map[user_input]
                    newly_labeled_rows.append(new_row)
                    break
                else:
                    print(">> ì˜ëª»ëœ ë¼ë²¨ì…ë‹ˆë‹¤. ë‹¤ì‹œ ì…ë ¥í•´ì£¼ì„¸ìš”. <<")
        labeled_df = pd.concat([labeled_df, pd.DataFrame(newly_labeled_rows)], ignore_index=True)
        unlabeled_pool_df = unlabeled_pool_df.drop(questions_to_label.index)

    # --- ìµœì¢… í‰ê°€ (ì•™ìƒë¸” ì˜ˆì¸¡) ---
    print("\n\n--- 4ë‹¨ê³„: ìµœì¢… ì„±ëŠ¥ í‰ê°€ ---")
    test_texts = test_df['text'].tolist()
    test_labels_cpu = test_df['label_id'].tolist()

    print("  - ìµœì¢… ì•™ìƒë¸” ëª¨ë¸ë¡œ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ ì„±ëŠ¥ ì¸¡ì • ì¤‘...")
    final_preds = ensemble_predict(model, model_snapshots, tokenizer, test_texts, device, PROMPT).numpy()

    final_accuracy = accuracy_score(test_labels_cpu, final_preds)
    print(f"  ğŸ“ [ìˆ˜ëŠ¥ ì‹œí—˜] ìµœì¢… ëª¨ë¸ì˜ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ ìµœì¢… ì •í™•ë„ (ì•™ìƒë¸”): {final_accuracy:.2%}")

    # --- ìµœì¢… ë¶„ì„ ë° ì‹œê°í™” ---
    print("\n" + "=" * 60);
    print("### ğŸ” 5ë‹¨ê³„: ìµœì¢… ëª¨ë¸ ì˜¤ë¥˜ ë¶„ì„ (ì˜¤ë‹µë…¸íŠ¸) ###");
    print("=" * 60)
    id_to_label_map = {v: k for k, v in label_map.items()}
    target_names = [name for name, id in sorted(label_map.items(), key=lambda item: item[1])]
    print(classification_report(test_labels_cpu, final_preds, target_names=target_names, zero_division=0))
    misclassified_indices = np.where(np.array(test_labels_cpu) != final_preds)[0]
    if len(misclassified_indices) > 0:
        print("\n--- ğŸ” ì˜ëª» ì˜ˆì¸¡ëœ ëŒ“ê¸€ ì˜ˆì‹œ (ìµœëŒ€ 10ê°œ) ---")
        for idx in misclassified_indices[:10]:
            print(
                f"\n  - ì‹¤ì œ: {id_to_label_map.get(test_labels_cpu[idx], 'N/A')}, ì˜ˆì¸¡: {id_to_label_map.get(final_preds[idx], 'N/A')}")
            print(f"  - ëŒ“ê¸€: {test_df.iloc[idx]['text']}")
        print("-" * 20)
    print("\n--- 6ë‹¨ê³„: ê²°ê³¼ ì‹œê°í™” ---")
    labeled_counts = [initial_labeled_count + i * QUERY_SIZE for i in range(len(validation_accuracies))]
    plt.figure(figsize=(10, 6));
    plt.plot(labeled_counts, validation_accuracies, marker='o', linestyle='-');
    plt.title('ì•¡í‹°ë¸Œ ëŸ¬ë‹ ë¼ë²¨ ìˆ˜ì— ë”°ë¥¸ ê²€ì¦ ì„¸íŠ¸ ì •í™•ë„ ë³€í™”');
    plt.xlabel('í•™ìŠµì— ì‚¬ìš©ëœ ë¼ë²¨ ë°ì´í„° ê°œìˆ˜');
    plt.ylabel('ê²€ì¦ ì„¸íŠ¸ ì •í™•ë„');
    plt.grid(True);
    plt.xticks(labeled_counts, rotation=45);
    plt.ylim(0, max(1.0, max(validation_accuracies, default=0) * 1.2));
    plt.gca().yaxis.set_major_formatter(plt.FuncFormatter(lambda y, _: f'{y:.0%}'));
    plt.tight_layout();
    plt.show()


if __name__ == "__main__":
    run_advanced_pipeline()